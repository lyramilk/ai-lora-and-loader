[paths]
# 基础路径配置
# Git代码仓库的根目录
data_dir = /home/lyramilk/ai/data
# 基础模型路径，用于训练和推理
model_path = /home/lyramilk/ai/Qwen2.5-Coder-3B-Instruct
# 模型输出目录，用于保存训练后的模型或LoRA权重
output_dir = /home/lyramilk/ai/Qwen2.5-Coder-3B-Instruct-finetune
# 数据集文件路径，用于保存收集的训练数据
dataset_path = code_dataset.json

[model]
# 模型训练配置
# 模型保存模式：lora(只保存LoRA权重), merge(保存合并后的完整模型), both(都保存)
save_mode = lora
# 量化方式：none(不量化), 4bit(4位量化), 8bit(8位量化)
quantization = none

[service]
# 服务配置
# 服务监听端口
port = 8080
# 服务监听地址，0.0.0.0表示监听所有地址
host = 0.0.0.0

[training]
# 训练参数
# 训练轮数
num_train_epochs = 3
# 每个设备的批次大小
per_device_train_batch_size = 2
# 梯度累积步数，用于模拟更大的批次大小
gradient_accumulation_steps = 8
# 学习率
learning_rate = 1e-4
# 权重衰减，用于防止过拟合
weight_decay = 0.01
# 预热比例，学习率从0增加到设定值的过程占总步数的比例
warmup_ratio = 0.1
# 日志记录步数，每多少步记录一次日志
logging_steps = 10
# 模型保存步数，每多少步保存一次模型
save_steps = 100
# 最多保存多少个检查点
save_total_limit = 3

[lora]
# LoRA配置
# LoRA秩，越大效果越好但参数量也越大
r = 8
# LoRA缩放因子，用于调节LoRA的影响程度
lora_alpha = 32
# LoRA dropout率，用于防止过拟合
lora_dropout = 0.05
# 需要应用LoRA的模块名称列表
target_modules = q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj

